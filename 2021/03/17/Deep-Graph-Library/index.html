<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Deep Graph Library"><meta name="keywords" content="DGL"><meta name="author" content="Alston"><meta name="copyright" content="Alston"><title>Deep Graph Library | Alston's blog</title><link rel="shortcut icon" href="/1231489.png"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-图"><span class="toc-text"> 1 图</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-图的基本概念"><span class="toc-text"> 1.1 图的基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-图-节点和边"><span class="toc-text"> 1.2 图、节点和边</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-节点和边的特征"><span class="toc-text"> 1.3 节点和边的特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-从外部源创建图"><span class="toc-text"> 1.4 从外部源创建图</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#从外部库创建图"><span class="toc-text"> 从外部库创建图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#从磁盘加载图"><span class="toc-text"> 从磁盘加载图</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#csv"><span class="toc-text"> CSV</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#jsongml-格式"><span class="toc-text"> JSON&#x2F;GML 格式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dgl-二进制格式"><span class="toc-text"> DGL 二进制格式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-异构图"><span class="toc-text"> 1.5 异构图</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#创建异构图"><span class="toc-text"> 创建异构图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用多种类型"><span class="toc-text"> 使用多种类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#边类型子图"><span class="toc-text"> 边类型子图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#将异构图转化为同构图"><span class="toc-text"> 将异构图转化为同构图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16-在gpu上使用dglgraph"><span class="toc-text"> 1.6 在GPU上使用DGLGraph</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-消息传递范式"><span class="toc-text"> 2 消息传递范式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#21-内置函数和消息传递api"><span class="toc-text"> 2.1 内置函数和消息传递API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#消息函数"><span class="toc-text"> 消息函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#聚合函数"><span class="toc-text"> 聚合函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#更新函数"><span class="toc-text"> 更新函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#code"><span class="toc-text"> Code</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#22-编写高效地消息传递代码"><span class="toc-text"> 2.2 编写高效地消息传递代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#23-在图的一部分上进行消息传递"><span class="toc-text"> 2.3 在图的一部分上进行消息传递</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#24-在消息传递中使用边的权重"><span class="toc-text"> 2.4 在消息传递中使用边的权重</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#25-在异构图上进行消息传递"><span class="toc-text"> 2.5 在异构图上进行消息传递</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://pic4.zhimg.com/80/v2-1b0d0240350e3d8e0550845b6bdaad1e_hd.jpg"></div><div class="author-info__name text-center">Alston</div><div class="author-info__description text-center">计算机硕士在读</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">49</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">27</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">13</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://blog.csdn.net/Sc0fie1d" target="_blank" rel="noopener">Alston's CSDN</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://s3.ax1x.com/2021/03/14/60DEdJ.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Alston's blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">Deep Graph Library</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-03-17</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">5.7k</span><span class="post-meta__separator">|</span><span>阅读时长: 23 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="1-图"><a class="markdownIt-Anchor" href="#1-图"></a> 1 图</h1>
<p>DGL通过其核心数据结构 <code>DGLGraph</code> 提供了一个以图为中心的编程抽象。 <code>DGLGraph</code> 提供了接口以处理图的结构、节点/边 的特征，以及使用这些组件可以执行的计算。</p>
<h2 id="11-图的基本概念"><a class="markdownIt-Anchor" href="#11-图的基本概念"></a> 1.1 图的基本概念</h2>
<p>DGL中图的类型包括：</p>
<blockquote>
<ul>
<li>同构图</li>
<li>异构图</li>
<li>二部图（特殊的异构图）</li>
<li>多重图（同一对节点之间有多条边，包括自循环的边）</li>
</ul>
</blockquote>
<h2 id="12-图-节点和边"><a class="markdownIt-Anchor" href="#12-图-节点和边"></a> 1.2 图、节点和边</h2>
<div style="border-radius: 3px;border-left: 4px solid #fa0;padding: 2px 5px 2px 10px;background-color: #ffaa0044;">
DGL使用一个唯一的整数来表示一个节点，称为点ID；并用对应的两个端点ID表示一条边。同时，DGL也会根据边被添加的顺序， 给每条边分配一个唯一的整数编号，称为边ID。节点和边的ID都是从0开始构建的。在DGL的图里，所有的边都是有方向的，即边 (u,v) 表示它是从节点 u 指向节点 v 的。
</div>
<p>DGL使用一个一维的整型<code>节点张量</code>来保存图的点ID，使用一个包含2个节点张量的元组 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>U</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(U,V)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mclose">)</span></span></span></span>，其中，用 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>U</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(U[i],V[i])</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mclose">]</span><span class="mclose">)</span></span></span></span> 指代一条 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>U</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">U[i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mclose">]</span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V[i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mclose">]</span></span></span></span> 的边。</p>
<p>下面的代码段使用了 <a href="https://docs.dgl.ai/en/latest/generated/dgl.graph.html#dgl.graph" target="_blank" rel="noopener"><code>dgl.graph()</code></a> 函数来构建一个 <a href="https://docs.dgl.ai/en/latest/api/python/dgl.DGLGraph.html#dgl.DGLGraph" target="_blank" rel="noopener"><code>DGLGraph</code></a> 对象:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line"></span><br><span class="line"><span class="comment"># 边 0-&gt;1, 0-&gt;2, 0-&gt;3, 1-&gt;3</span></span><br><span class="line">u, v = th.tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">g = dgl.graph((u, v))</span><br><span class="line">print(g) <span class="comment"># 图中节点的数量是DGL通过给定的图的边列表中最大的点ID推断所得出的</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Graph(num_nodes=4, num_edges=4,</span></span><br><span class="line"><span class="string">      ndata_schemes=&#123;&#125;</span></span><br><span class="line"><span class="string">      edata_schemes=&#123;&#125;)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># 获取节点的ID</span></span><br><span class="line">print(g.nodes())</span><br><span class="line"><span class="comment"># tensor([0, 1, 2, 3])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取边的对应端点</span></span><br><span class="line">print(g.edges())</span><br><span class="line"><span class="comment"># (tensor([0, 0, 0, 1]), tensor([1, 2, 3, 3]))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取边的对应端点和边ID</span></span><br><span class="line">print(g.edges(form=<span class="string">'all'</span>))</span><br><span class="line"><span class="comment"># (tensor([0, 0, 0, 1]), tensor([1, 2, 3, 3]), tensor([0, 1, 2, 3]))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果具有最大ID的节点没有边，在创建图的时候，用户需要明确地指明节点的数量。</span></span><br><span class="line">g = dgl.graph((u, v), num_nodes=<span class="number">8</span>)</span><br><span class="line"><span class="comment"># 这样创建了节点4-7，但其不存在边</span></span><br></pre></td></tr></table></figure>
<p>创建无向图需要使用<a href="https://docs.dgl.ai/en/latest/generated/dgl.to_bidirected.html#dgl.to_bidirected" target="_blank" rel="noopener"><code>dgl.to_bidirected()</code></a> 函数为每条边都创建两个方向的边：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bg = dgl.to_bidirected(g)</span><br><span class="line">bg.edges()</span><br><span class="line"><span class="comment"># (tensor([0, 0, 0, 1, 1, 2, 3, 3]), tensor([1, 2, 3, 0, 3, 0, 0, 1]))</span></span><br></pre></td></tr></table></figure>
<div style="border-radius: 3px;border-left: 4px solid #338af4;padding: 2px 5px 2px 10px;background-color: #338af444;">
    由于Tensor类内部使用C来存储，且显性定义了数据类型以及存储的设备信息，DGL推荐使用Tensor作为DGL API的输入。 不过大部分的DGL API也支持Python的可迭代类型(比如列表)或numpy.ndarray类型作为API的输入，方便用户快速进行开发验证。
</div>
<div style="border-radius: 3px;border-left: 4px solid #338af4;padding: 2px 5px 2px 10px;background-color: #338af444;">
    DGL支持使用 32 位或 64 位的整数作为节点ID和边ID。节点和边ID的数据类型必须一致。如果图里的节点或者边的数量小于 2^{63}−1 ，用户最好使用 32 位整数。 这样不仅能提升速度，还能减少内存的使用。DGL提供了进行数据类型转换的方法，如下例所示:
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">edges = th.tensor([<span class="number">2</span>, <span class="number">5</span>, <span class="number">3</span>]), th.tensor([<span class="number">3</span>, <span class="number">5</span>, <span class="number">0</span>])  <span class="comment"># 边：2-&gt;3, 5-&gt;5, 3-&gt;0</span></span><br><span class="line">g64 = dgl.graph(edges)  <span class="comment"># DGL默认使用int64</span></span><br><span class="line">g32 = dgl.graph(edges, idtype=th.int32)  <span class="comment"># 使用int32构建图</span></span><br><span class="line">g64_2 = g32.long()  <span class="comment"># 转换成int64</span></span><br><span class="line">g32_2 = g64.int()  <span class="comment"># 转换成int32</span></span><br></pre></td></tr></table></figure>
<h2 id="13-节点和边的特征"><a class="markdownIt-Anchor" href="#13-节点和边的特征"></a> 1.3 节点和边的特征</h2>
<p><a href="https://docs.dgl.ai/en/latest/api/python/dgl.DGLGraph.html#dgl.DGLGraph" target="_blank" rel="noopener"><code>DGLGraph</code></a> 对象的节点和边可具有多个用户定义的、可命名的特征，可以通过 <a href="https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.ndata.html#dgl.DGLGraph.ndata" target="_blank" rel="noopener"><code>ndata</code></a> 和 <a href="https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.edata.html#dgl.DGLGraph.edata" target="_blank" rel="noopener"><code>edata</code></a> 接口可访问：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>])) <span class="comment"># 6个节点，4条边</span></span><br><span class="line"></span><br><span class="line">g.ndata[<span class="string">'x'</span>] = th.ones(g.num_nodes(), <span class="number">3</span>)               <span class="comment"># 长度为3的节点特征</span></span><br><span class="line">g.edata[<span class="string">'x'</span>] = th.ones(g.num_edges(), dtype=th.int32)  <span class="comment"># 标量整型特征</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Graph(num_nodes=6, num_edges=4,</span></span><br><span class="line"><span class="string">      ndata_schemes=&#123;'x' : Scheme(shape=(3,), dtype=torch.float32)&#125;</span></span><br><span class="line"><span class="string">      edata_schemes=&#123;'x' : Scheme(shape=(,), dtype=torch.int32)&#125;)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同名称的特征可以具有不同shape</span></span><br><span class="line">g.ndata[<span class="string">'y'</span>] = th.randn(g.num_nodes(), <span class="number">5</span>)</span><br><span class="line">g.ndata[<span class="string">'x'</span>][<span class="number">1</span>]                  <span class="comment"># 获取节点1的特征</span></span><br><span class="line">g.edata[<span class="string">'x'</span>][th.tensor([<span class="number">0</span>, <span class="number">3</span>])]  <span class="comment"># 获取边0和3的特征</span></span><br></pre></td></tr></table></figure>
<div style="border-radius: 3px;border-left: 4px solid #fa0;padding: 2px 5px 2px 10px;background-color: #ffaa0044;">
    关于 ndata 和 edata 接口的重要说明：
</div>
<ul>
<li><strong>仅允许使用数值类型</strong>（如单精度浮点型、双精度浮点型和整型）的特征。这些特征可以是标量、向量或多维张量。</li>
<li>每个节点特征具有唯一名称，每个边特征也具有唯一名称。节点和边的特征可以具有相同的名称（如上述示例代码中的 <code>'x'</code> ）。</li>
<li>通过张量分配创建特征时，DGL会将特征赋给图中的每个节点和每条边。<strong>该张量的第一维必须与图中节点或边的数量一致。 不能将特征赋给图中节点或边的子集。</strong></li>
<li>相同名称的特征必须具有相同的维度和数据类型。</li>
<li>特征张量使用”行优先”的原则，即<strong>每个行切片储存1个节点或1条边的特征</strong>。</li>
</ul>
<p>对于加权图，用户可以将权重储存为一个边特征：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 边 0-&gt;1, 0-&gt;2, 0-&gt;3, 1-&gt;3</span></span><br><span class="line">edges = th.tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">weights = th.tensor([<span class="number">0.1</span>, <span class="number">0.6</span>, <span class="number">0.9</span>, <span class="number">0.7</span>])  <span class="comment"># 每条边的权重</span></span><br><span class="line">g = dgl.graph(edges)</span><br><span class="line">g.edata[<span class="string">'w'</span>] = weights  <span class="comment"># 将其命名为 'w'</span></span><br></pre></td></tr></table></figure>
<h2 id="14-从外部源创建图"><a class="markdownIt-Anchor" href="#14-从外部源创建图"></a> 1.4 从外部源创建图</h2>
<p>可以从外部来源构造一个 <a href="https://docs.dgl.ai/en/latest/api/python/dgl.DGLGraph.html#dgl.DGLGraph" target="_blank" rel="noopener"><code>DGLGraph</code></a> 对象</p>
<h3 id="从外部库创建图"><a class="markdownIt-Anchor" href="#从外部库创建图"></a> 从外部库创建图</h3>
<p>以下代码片段为从 SciPy 稀疏矩阵和 NetworkX 图创建 DGL 图的示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line">spmat = sp.rand(<span class="number">100</span>, <span class="number">100</span>, density=<span class="number">0.05</span>) <span class="comment"># 5%非零项</span></span><br><span class="line">dgl.from_scipy(spmat)                   <span class="comment"># 来自SciPy</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">num_edges = 0.05*100*100</span></span><br><span class="line"><span class="string">Graph(num_nodes=100, num_edges=500, </span></span><br><span class="line"><span class="string">      ndata_schemes=&#123;&#125;</span></span><br><span class="line"><span class="string">      edata_schemes=&#123;&#125;)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line">nx_g = nx.path_graph(<span class="number">5</span>) <span class="comment"># 一条链路0-1-2-3-4</span></span><br><span class="line">dgl.from_networkx(nx_g) <span class="comment"># 来自NetworkX</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Graph(num_nodes=5, num_edges=8,</span></span><br><span class="line"><span class="string">      ndata_schemes=&#123;&#125;</span></span><br><span class="line"><span class="string">      edata_schemes=&#123;&#125;)</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<p>注意，当使用 nx.path_graph(5) 进行创建时， <a href="https://docs.dgl.ai/en/latest/api/python/dgl.DGLGraph.html#dgl.DGLGraph" target="_blank" rel="noopener"><code>DGLGraph</code></a> 对象有8条边，而非4条。 这是由于 nx.path_graph(5) 构建了一个无向的NetworkX图 <a href="https://networkx.org/documentation/stable/reference/classes/graph.html#networkx.Graph" target="_blank" rel="noopener"><code>networkx.Graph</code></a> ，而 <a href="https://docs.dgl.ai/en/latest/api/python/dgl.DGLGraph.html#dgl.DGLGraph" target="_blank" rel="noopener"><code>DGLGraph</code></a> 的边总是有向的。 所以当将无向的NetworkX图转换为 <a href="https://docs.dgl.ai/en/latest/api/python/dgl.DGLGraph.html#dgl.DGLGraph" target="_blank" rel="noopener"><code>DGLGraph</code></a> 对象时，DGL会在内部将1条无向边转换为2条有向边。 使用有向的NetworkX图 <a href="https://networkx.org/documentation/stable/reference/classes/digraph.html#networkx.DiGraph" target="_blank" rel="noopener"><code>networkx.DiGraph</code></a> 可避免该行为。</p>
<h3 id="从磁盘加载图"><a class="markdownIt-Anchor" href="#从磁盘加载图"></a> 从磁盘加载图</h3>
<h4 id="csv"><a class="markdownIt-Anchor" href="#csv"></a> CSV</h4>
<h4 id="jsongml-格式"><a class="markdownIt-Anchor" href="#jsongml-格式"></a> JSON/GML 格式</h4>
<h4 id="dgl-二进制格式"><a class="markdownIt-Anchor" href="#dgl-二进制格式"></a> DGL 二进制格式</h4>
<p>相关API： <a href="https://docs.dgl.ai/en/latest/generated/dgl.save_graphs.html#dgl.save_graphs" target="_blank" rel="noopener"><code>dgl.save_graphs()</code></a>、 <a href="https://docs.dgl.ai/en/latest/generated/dgl.load_graphs.html#dgl.load_graphs" target="_blank" rel="noopener"><code>dgl.load_graphs()</code></a></p>
<div style="border-radius: 3px;border-left: 4px solid #338af4;padding: 2px 5px 2px 10px;background-color: #338af444;">
dgl.save_graphs(filename, g_list, labels=None)
</div>
<ul>
<li><strong>filename</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str" target="_blank" rel="noopener"><em>str</em></a>) – The file name to store the graphs and labels.</li>
<li><strong>g_list</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#list" target="_blank" rel="noopener"><em>list</em></a>) – The graphs to be saved.</li>
<li><strong>labels</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#dict" target="_blank" rel="noopener"><em>dict</em></a><em>[</em><a href="https://docs.python.org/3/library/stdtypes.html#str" target="_blank" rel="noopener"><em>str</em></a><em>,</em> Tensor]) – labels should be dict of tensors, with str as keys</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> dgl.data.utils <span class="keyword">import</span> save_graphs</span><br><span class="line"></span><br><span class="line">graph_labels = &#123;<span class="string">"glabel"</span>: th.tensor([<span class="number">0</span>, <span class="number">1</span>])&#125;</span><br><span class="line">save_graphs(<span class="string">"./data.bin"</span>, [g1, g2], graph_labels)</span><br></pre></td></tr></table></figure>
<div style="border-radius: 3px;border-left: 4px solid #338af4;padding: 2px 5px 2px 10px;background-color: #338af444;">
dgl.load_graphs(filename, idx_list=None)
</div>
<p>Parameters</p>
<ul>
<li><strong>filename</strong> (str) – The file name to load graphs from.</li>
<li><strong>idx_list</strong> (list[int], optional) – The indices of the graphs to be loaded if the file contains multiple graphs. Default is loading all the graphs stored in the file.</li>
</ul>
<p>Returns</p>
<ul>
<li><strong>graph_list</strong> (list[DGLGraph]) – The loaded graphs.</li>
<li><strong>labels</strong> (dict[str, Tensor]) – The graph labels stored in file. If no label is stored, the dictionary is empty. Regardless of whether the <code>idx_list</code> argument is given or not, the returned dictionary always contains the labels of all the graphs.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> dgl.data.utils <span class="keyword">import</span> load_graphs</span><br><span class="line">glist, label_dict = load_graphs(<span class="string">"./data.bin"</span>) <span class="comment"># glist will be [g1, g2]</span></span><br><span class="line">glist, label_dict = load_graphs(<span class="string">"./data.bin"</span>, [<span class="number">0</span>]) <span class="comment"># glist will be [g1]</span></span><br></pre></td></tr></table></figure>
<h2 id="15-异构图"><a class="markdownIt-Anchor" href="#15-异构图"></a> 1.5 异构图</h2>
<p>异构图中不同类型的节点和边具有<strong>独立的</strong>ID空间和特征。在DGL中，一个异构图由一系列子图构成，一个子图对应一种关系。每个关系由一个字符串三元组 定义 <code>(源节点类型, 边类型, 目标节点类型)</code> 。</p>
<h3 id="创建异构图"><a class="markdownIt-Anchor" href="#创建异构图"></a> 创建异构图</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个具有3种节点类型和3种边类型的异构图</span></span><br><span class="line">graph_data = &#123;</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'drug'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>])),</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'gene'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">2</span>, <span class="number">3</span>])),</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'treats'</span>, <span class="string">'disease'</span>): (th.tensor([<span class="number">1</span>]), th.tensor([<span class="number">2</span>]))</span><br><span class="line">&#125;</span><br><span class="line">g = dgl.heterograph(graph_data)</span><br><span class="line">g.ntypes</span><br><span class="line"><span class="comment"># ['disease', 'drug', 'gene']</span></span><br><span class="line">g.etypes</span><br><span class="line"><span class="comment"># ['interacts', 'interacts', 'treats']</span></span><br><span class="line">g.canonical_etypes</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">[('drug', 'interacts', 'drug'),</span></span><br><span class="line"><span class="string"> ('drug', 'interacts', 'gene'),</span></span><br><span class="line"><span class="string"> ('drug', 'treats', 'disease')]</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<div style="border-radius: 3px;border-left: 4px solid #338af4;padding: 2px 5px 2px 10px;background-color: #338af444;">
    与异构图相关联的 metagraph 就是图的模式。它指定节点集和节点之间的边的类型约束。 metagraph 中的一个节点 u 对应于相关异构图中的一个节点类型。 metagraph 中的边 (u,v) 表示在相关异构图中存在从 u 型节点到 v 型节点的边。
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Graph(num_nodes=&#123;'disease': 3, 'drug': 3, 'gene': 4&#125;,</span></span><br><span class="line"><span class="string">      num_edges=&#123;('drug', 'interacts', 'drug'): 2,</span></span><br><span class="line"><span class="string">                 ('drug', 'interacts', 'gene'): 2,</span></span><br><span class="line"><span class="string">                 ('drug', 'treats', 'disease'): 1&#125;,</span></span><br><span class="line"><span class="string">      metagraph=[('drug', 'drug', 'interacts'),</span></span><br><span class="line"><span class="string">                 ('drug', 'gene', 'interacts'),</span></span><br><span class="line"><span class="string">                 ('drug', 'disease', 'treats')])</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">g.metagraph().edges()</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">OutMultiEdgeDataView([('drug', 'drug'), ('drug', 'gene'), ('drug', 'disease')])</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">g.metagraph().nodes()</span><br><span class="line"><span class="comment"># ['drug', 'gene', 'disease']</span></span><br></pre></td></tr></table></figure>
<h3 id="使用多种类型"><a class="markdownIt-Anchor" href="#使用多种类型"></a> 使用多种类型</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取图中所有节点的数量</span></span><br><span class="line">g.num_nodes()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取drug节点的数量</span></span><br><span class="line">g.num_nodes(<span class="string">'drug'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同类型的节点有单独的ID。因此，没有指定节点类型就没有明确的返回值。</span></span><br><span class="line">g.nodes()  <span class="comment">#DGLError</span></span><br><span class="line">g.nodes(<span class="string">'drug'</span>)</span><br><span class="line"><span class="comment"># tensor([0, 1, 2])</span></span><br></pre></td></tr></table></figure>
<p><strong>设置/获取特定节点和边类型的特征</strong>：</p>
<div style="border-radius: 3px;border-left: 4px solid #338af4;padding: 2px 5px 2px 10px;background-color: #338af444;">
    g.nodes[‘node_type’].data[‘feat_name’]
</div>
<div style="border-radius: 3px;border-left: 4px solid #338af4;padding: 2px 5px 2px 10px;background-color: #338af444;">
g.edges[‘edge_type’].data[‘feat_name’] 
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置/获取"drug"类型的节点的"hv"特征</span></span><br><span class="line">g.nodes[<span class="string">'drug'</span>].data[<span class="string">'hv'</span>] = th.ones(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">g.nodes[<span class="string">'drug'</span>].data[<span class="string">'hv'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置/获取"treats"类型的边的"he"特征</span></span><br><span class="line">g.edges[<span class="string">'treats'</span>].data[<span class="string">'he'</span>] = th.zeros(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">g.edges[<span class="string">'treats'</span>].data[<span class="string">'he'</span>]</span><br></pre></td></tr></table></figure>
<p>如果图里只有一种节点或边类型，则不需要指定节点或边的类型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = dgl.heterograph(&#123;</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'drug'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>])),</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'is similar'</span>, <span class="string">'drug'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line">&#125;)</span><br><span class="line">g.nodes()</span><br><span class="line">g.ndata[<span class="string">'hv'</span>] = th.ones(<span class="number">4</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<div style="border-radius: 3px;border-left: 4px solid #338af4;padding: 2px 5px 2px 10px;background-color: #338af444;">
当边类型唯一地确定了源节点和目标节点的类型时，用户可以只使用一个字符串而不是字符串三元组来指定边类型。例如， 对于具有两个关系 ('user', 'plays', 'game') 和 ('user', 'likes', 'game') 的异构图， 只使用 'plays' 或 'like' 来指代这两个关系是可以的。否则，需要使用三元组指定
</div>
<h3 id="边类型子图"><a class="markdownIt-Anchor" href="#边类型子图"></a> 边类型子图</h3>
<p>用户可以通过<strong>指定要保留的关系来创建异构图的子图</strong>，相关的特征也会被拷贝。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = dgl.heterograph(&#123;</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'drug'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>])),</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'gene'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">2</span>, <span class="number">3</span>])),</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'treats'</span>, <span class="string">'disease'</span>): (th.tensor([<span class="number">1</span>]), th.tensor([<span class="number">2</span>]))</span><br><span class="line">&#125;)</span><br><span class="line">g.nodes[<span class="string">'drug'</span>].data[<span class="string">'hv'</span>] = th.ones(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留关系 ('drug', 'interacts', 'drug') 和 ('drug', 'treats', 'disease') 。</span></span><br><span class="line"><span class="comment"># 'drug' 和 'disease' 类型的节点也会被保留</span></span><br><span class="line">eg = dgl.edge_type_subgraph(g, [(<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'drug'</span>),</span><br><span class="line">                                (<span class="string">'drug'</span>, <span class="string">'treats'</span>, <span class="string">'disease'</span>)])</span><br><span class="line">eg</span><br><span class="line"><span class="comment"># 相关的特征也会被拷贝</span></span><br><span class="line">eg.nodes[<span class="string">'drug'</span>].data[<span class="string">'hv'</span>]</span><br></pre></td></tr></table></figure>
<h3 id="将异构图转化为同构图"><a class="markdownIt-Anchor" href="#将异构图转化为同构图"></a> 将异构图转化为同构图</h3>
<p>DGL允许使用 <code>dgl.DGLGraph.to_homogeneous()</code> API将异构图转换为同构图：</p>
<div style="border-radius: 3px;border-left: 4px solid #338af4;padding: 2px 5px 2px 10px;background-color: #338af444;">
1. 用从0开始的连续整数重新标记所有类型的节点和边。
</div>
<div style="border-radius: 3px;border-left: 4px solid #338af4;padding: 2px 5px 2px 10px;background-color: #338af444;">
2. 对所有的节点和边合并用户指定的特征。
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = dgl.heterograph(&#123;</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'drug'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>])),</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'treats'</span>, <span class="string">'disease'</span>): (th.tensor([<span class="number">1</span>]), th.tensor([<span class="number">2</span>]))&#125;)</span><br><span class="line">g.nodes[<span class="string">'drug'</span>].data[<span class="string">'hv'</span>] = th.zeros(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">g.nodes[<span class="string">'disease'</span>].data[<span class="string">'hv'</span>] = th.ones(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">g.edges[<span class="string">'interacts'</span>].data[<span class="string">'he'</span>] = th.zeros(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">g.edges[<span class="string">'treats'</span>].data[<span class="string">'he'</span>] = th.zeros(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认情况下不进行特征拷贝</span></span><br><span class="line">hg = dgl.to_homogeneous(g)</span><br><span class="line"><span class="string">'hv'</span> <span class="keyword">in</span> hg.ndata</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝边的特征</span></span><br><span class="line"><span class="comment"># 对于要拷贝的特征，DGL假定不同类型的节点或边的需要合并的特征具有相同的大小和数据类型</span></span><br><span class="line">hg = dgl.to_homogeneous(g, edata=[<span class="string">'he'</span>])</span><br><span class="line"><span class="comment"># 报错：interacts的特征维度为1，而treats为2</span></span><br><span class="line"><span class="comment"># DGLError: Cannot concatenate column ‘he’ with shape Scheme(shape=(2,), dtype=torch.float32) and shape Scheme(shape=(1,), dtype=torch.float32)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝节点特征</span></span><br><span class="line">hg = dgl.to_homogeneous(g, ndata=[<span class="string">'hv'</span>])</span><br><span class="line">hg.ndata[<span class="string">'hv'</span>]</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">tensor([[1.],</span></span><br><span class="line"><span class="string">        [1.],</span></span><br><span class="line"><span class="string">        [1.],</span></span><br><span class="line"><span class="string">        [0.],</span></span><br><span class="line"><span class="string">        [0.],</span></span><br><span class="line"><span class="string">        [0.]])</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<p>原始的节点或边的类型和对应的ID被存储在 <a href="https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.ndata.html#dgl.DGLGraph.ndata" target="_blank" rel="noopener"><code>ndata</code></a> 和 <a href="https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.edata.html#dgl.DGLGraph.edata" target="_blank" rel="noopener"><code>edata</code></a> 中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 异构图中节点类型的顺序</span></span><br><span class="line">g.ntypes   <span class="comment"># ['disease', 'drug']</span></span><br><span class="line"><span class="comment"># 原始节点类型</span></span><br><span class="line">hg.ndata[dgl.NTYPE]   <span class="comment"># tensor([0, 0, 0, 1, 1, 1])</span></span><br><span class="line"><span class="comment"># 原始的特定类型节点ID</span></span><br><span class="line">hg.ndata[dgl.NID]   <span class="comment"># tensor([0, 1, 2, 0, 1, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 异构图中边类型的顺序</span></span><br><span class="line">g.etypes   <span class="comment"># ['interacts', 'treats']</span></span><br><span class="line"><span class="comment"># 原始边类型   </span></span><br><span class="line">hg.edata[dgl.ETYPE]   <span class="comment"># tensor([0, 0, 1])</span></span><br><span class="line"><span class="comment"># 原始的特定类型边ID</span></span><br><span class="line">hg.edata[dgl.EID]   <span class="comment"># tensor([0, 1, 0])</span></span><br></pre></td></tr></table></figure>
<p>出于建模的目的，用户可能需要将一些关系合并，并对它们应用相同的操作。为了实现这一目的，可以<strong>先抽取异构图的边类型子图，然后将该子图转换为同构图</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = dgl.heterograph(&#123;</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'drug'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>])),</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'gene'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">2</span>, <span class="number">3</span>])),</span><br><span class="line">   (<span class="string">'drug'</span>, <span class="string">'treats'</span>, <span class="string">'disease'</span>): (th.tensor([<span class="number">1</span>]), th.tensor([<span class="number">2</span>]))</span><br><span class="line">&#125;)</span><br><span class="line">sub_g = dgl.edge_type_subgraph(g, [(<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'drug'</span>),</span><br><span class="line">                                   (<span class="string">'drug'</span>, <span class="string">'interacts'</span>, <span class="string">'gene'</span>)])</span><br><span class="line">h_sub_g = dgl.to_homogeneous(sub_g)</span><br><span class="line">h_sub_g</span><br></pre></td></tr></table></figure>
<h2 id="16-在gpu上使用dglgraph"><a class="markdownIt-Anchor" href="#16-在gpu上使用dglgraph"></a> 1.6 在GPU上使用DGLGraph</h2>
<p>用户可以通过在构造过程中传入两个GPU张量来创建GPU上的 <a href="https://docs.dgl.ai/en/latest/api/python/dgl.DGLGraph.html#dgl.DGLGraph" target="_blank" rel="noopener"><code>DGLGraph</code></a> 。 另一种方法是使用 <a href="https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.to.html#dgl.DGLGraph.to" target="_blank" rel="noopener"><code>to()</code></a> API将 <a href="https://docs.dgl.ai/en/latest/api/python/dgl.DGLGraph.html#dgl.DGLGraph" target="_blank" rel="noopener"><code>DGLGraph</code></a> 复制到GPU，这会将图结构和特征数据都拷贝到指定的设备。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line">u, v = th.tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]), th.tensor([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">g = dgl.graph((u, v))</span><br><span class="line">g.ndata[<span class="string">'x'</span>] = th.randn(<span class="number">5</span>, <span class="number">3</span>)   <span class="comment"># 原始特征在CPU上</span></span><br><span class="line">g.device</span><br><span class="line"><span class="comment"># device(type='cpu')</span></span><br><span class="line"></span><br><span class="line">cuda_g = g.to(<span class="string">'cuda:0'</span>)         <span class="comment"># 接受来自后端框架的任何设备对象</span></span><br><span class="line">cuda_g.device</span><br><span class="line"><span class="comment"># device(type='cuda', index=0)</span></span><br><span class="line">cuda_g.ndata[<span class="string">'x'</span>].device        <span class="comment"># 特征数据也拷贝到了GPU上</span></span><br><span class="line"><span class="comment"># device(type='cuda', index=0)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 由GPU张量构造的图也在GPU上</span></span><br><span class="line">u, v = u.to(<span class="string">'cuda:0'</span>), v.to(<span class="string">'cuda:0'</span>)</span><br><span class="line">g = dgl.graph((u, v))</span><br><span class="line">g.device</span><br><span class="line"><span class="comment"># device(type='cuda', index=0)</span></span><br></pre></td></tr></table></figure>
<p>任何涉及GPU图的操作都是在GPU上运行的。因此，这要求所有张量参数都已经放在GPU上，其结果(图或张量)也将在GPU上。 此外，GPU图只接受GPU上的特征数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cuda_g.in_degrees()</span><br><span class="line"><span class="comment">#tensor([0, 0, 1, 1, 1], device='cuda:0')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dgl.DGLGraph.in_edges():Return the incoming edges of the given nodes.</span></span><br><span class="line">cuda_g.in_edges([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])         <span class="comment"># 可以接受非张量类型的参数</span></span><br><span class="line"><span class="comment"># (tensor([0, 1, 2], device='cuda:0'), tensor([2, 3, 4], device='cuda:0'))</span></span><br><span class="line"></span><br><span class="line">cuda_g.in_edges(th.tensor([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]).to(<span class="string">'cuda:0'</span>))  <span class="comment"># 张量类型的参数必须在GPU上</span></span><br><span class="line"><span class="comment"># (tensor([0, 1, 2], device='cuda:0'), tensor([2, 3, 4], device='cuda:0'))</span></span><br><span class="line"></span><br><span class="line">cuda_g.ndata[<span class="string">'h'</span>] = th.randn(<span class="number">5</span>, <span class="number">4</span>)     <span class="comment"># ERROR! 特征也必须在GPU上！</span></span><br></pre></td></tr></table></figure>
<h1 id="2-消息传递范式"><a class="markdownIt-Anchor" href="#2-消息传递范式"></a> 2 消息传递范式</h1>
<p>消息传递是Deep Graph Library (DGL) 实现GNN的一种通用框架和编程范式。它从聚合与更新的角度归纳总结了多种GNN模型的实现。假设节点 v 上的特征为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">x_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，边 (u, v) 上的特征为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">w_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Edge-wise: </mtext><msubsup><mi>m</mi><mi>e</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mi>ϕ</mi><mrow><mo fence="true">(</mo><msubsup><mi>x</mi><mi>v</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><msubsup><mi>x</mi><mi>u</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><msubsup><mi>w</mi><mi>e</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo separator="true">,</mo><mi>e</mi><mo stretchy="false">)</mo><mo>∈</mo><mi mathvariant="script">E</mi></mrow><annotation encoding="application/x-tex">\text{Edge-wise: } m_{e}^{(t+1)} = \phi \left( x_v^{(t)}, x_u^{(t)}, w_{e}^{(t)} \right) , ({u}, {v},{e}) \in \mathcal{E}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185em;vertical-align:-0.247em;"></span><span class="mord text"><span class="mord">Edge-wise: </span></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mord mathdefault">ϕ</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">u</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">u</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">e</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08944em;">E</span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Node-wise: </mtext><msubsup><mi>x</mi><mi>v</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mi>ψ</mi><mrow><mo fence="true">(</mo><msubsup><mi>x</mi><mi>v</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><mi>ρ</mi><mrow><mo fence="true">(</mo><mrow><mo fence="true">{</mo><msubsup><mi>m</mi><mi>e</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>:</mo><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo separator="true">,</mo><mi>e</mi><mo stretchy="false">)</mo><mo>∈</mo><mi mathvariant="script">E</mi><mo fence="true">}</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{Node-wise: } x_v^{(t+1)} = \psi \left(x_v^{(t)}, \rho\left(\left\lbrace m_{e}^{(t+1)} : ({u}, {v},{e}) \in \mathcal{E} \right\rbrace \right) \right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185em;vertical-align:-0.247em;"></span><span class="mord text"><span class="mord">Node-wise: </span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ψ</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">ρ</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">{</span></span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">u</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">e</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08944em;">E</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">}</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></span></p>
<ul>
<li>
<p>消息函数 (Message Function) <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">ϕ</span></span></span></span>：定义在每条边上，通过combine边上和两端节点的特征来生成消息</p>
</li>
<li>
<p>聚合函数 (Reduce Function) <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ρ</mi></mrow><annotation encoding="application/x-tex">\rho</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">ρ</span></span></span></span>：通过mailbox来聚合节点接收到的消息</p>
</li>
<li>
<p>更新函数 (Update Function) <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ψ</mi></mrow><annotation encoding="application/x-tex">\psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ψ</span></span></span></span>：结合聚合后的消息和节点本身的特征来更新节点特征</p>
</li>
</ul>
<h2 id="21-内置函数和消息传递api"><a class="markdownIt-Anchor" href="#21-内置函数和消息传递api"></a> 2.1 内置函数和消息传递API</h2>
<p>DGL在命名空间 <code>dgl.function</code> 中实现了常用的消息函数和聚合函数作为 <a href="https://docs.dgl.ai/en/latest/api/python/dgl.function.html#api-built-in" target="_blank" rel="noopener"><strong>内置函数</strong></a>。 一般来说，DGL建议 <strong>尽可能</strong> 使用内置函数，因为它们经过了大量优化，并且可以自动处理维度广播。</p>
<h3 id="消息函数"><a class="markdownIt-Anchor" href="#消息函数"></a> 消息函数</h3>
<p>在DGL中，<strong>消息函数</strong> 接受一个参数 <code>edges</code>，这是一个 <code>EdgeBatch</code> 的实例， 在消息传递时，它被DGL在内部生成以表示一批边。 <code>edges</code> 有 <code>src</code>、 <code>dst</code> 和 <code>data</code> 共3个成员属性， 分别用于访问源节点、目标节点和边的特征。</p>
<p>消息的内置函数的命名约定是 <code>u</code> 表示 <code>源</code> 节点， <code>v</code> 表示 <code>目标</code> 节点，<code>e</code> 表示 <code>边</code>。例如，要对源节点的 <code>hu</code> 特征和目标节点的 <code>hv</code> 特征求和， 然后将结果保存在边的 <code>he</code> 特征上，用户可以使用内置函数<code>dgl.function.u_add_v('hu', 'hv', 'he')</code>。</p>
<h3 id="聚合函数"><a class="markdownIt-Anchor" href="#聚合函数"></a> 聚合函数</h3>
<p>接受一个参数 <code>nodes</code>，这是一个 <code>NodeBatch</code> 的实例， 在消息传递时，它被DGL在内部生成以表示一批节点。 <code>nodes</code> 的成员属性 <code>mailbox</code> 可以用来访问节点收到的消息。 一些最常见的聚合操作包括 <code>sum</code>、<code>max</code>、<code>min</code> 等。</p>
<p>DGL支持内置的聚合函数 <code>sum</code>、 <code>max</code>、 <code>min</code> 和 <code>mean</code> 操作。 聚合函数通常有两个参数，它们的类型都是字符串。一个用于指定 <code>mailbox</code> 中的字段名，一个用于指示目标节点特征的字段名， 例如， <code>dgl.function.sum('m', 'h')</code></p>
<h3 id="更新函数"><a class="markdownIt-Anchor" href="#更新函数"></a> 更新函数</h3>
<p>接受一个如上所述的参数 <code>nodes</code>。此函数对 <code>聚合函数</code> 的聚合结果进行操作， 通常在消息传递的最后一步将其与节点的特征相结合，并将输出作为节点的新特征。</p>
<h3 id="code"><a class="markdownIt-Anchor" href="#code"></a> Code</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line"><span class="keyword">import</span> dgl.function <span class="keyword">as</span> fn</span><br><span class="line"></span><br><span class="line"><span class="comment"># UDF Message Function</span></span><br><span class="line"><span class="comment"># 等价于 fn.u_add_v('feat', 'feat', 'm')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">message_func</span><span class="params">(edges)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'m'</span>: edges.src[<span class="string">'feat'</span>] + edges.dst[<span class="string">'feat'</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># UDF Reduce Function</span></span><br><span class="line"><span class="comment"># 等价于 fn.sum('m', 'h')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce_func</span><span class="params">(nodes)</span>:</span></span><br><span class="line">    <span class="comment"># mailbox['m']的shape: (节点数, 邻居数, 特征维度)</span></span><br><span class="line">     <span class="keyword">return</span> &#123;<span class="string">'h'</span>: th.sum(nodes.mailbox[<span class="string">'m'</span>], dim=<span class="number">1</span>)&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># update_all() 的参数是一个消息函数、一个聚合函数和一个更新函数。更新函数是一个可选择的参数，</span></span><br><span class="line"><span class="comment"># 用户也可以不使用它，而是在 update_all 执行完后直接对节点特征进行操作。</span></span><br><span class="line"><span class="comment"># 由于更新函数通常可以用纯张量操作实现，所以DGL不推荐在 update_all 中指定更新函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updata_all_example</span><span class="params">(graph)</span>:</span></span><br><span class="line">    <span class="comment"># 在graph.ndata['ft']中存储结果</span></span><br><span class="line">    graph.update_all(fn.u_mul_e(<span class="string">'feat'</span>, <span class="string">'a'</span>, <span class="string">'m'</span>),</span><br><span class="line">                     fn.sum(<span class="string">'m'</span>, <span class="string">'feat'</span>))</span><br><span class="line">    <span class="comment"># 在update_all外进行最终操作并更新节点嵌入</span></span><br><span class="line">    final_ft = graph.ndata[<span class="string">'feat'</span>] * <span class="number">2</span></span><br><span class="line">    graph.ndata[<span class="string">'feat'</span>] = final_ft</span><br><span class="line">    <span class="keyword">return</span> graph</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    u, v = th.tensor([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]), th.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">    g = dgl.graph((u,v))</span><br><span class="line">    g.ndata[<span class="string">'feat'</span>] = th.ones(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 单独调用消息函数和聚合函数并不会在节点或边上保存计算结果</span></span><br><span class="line">    <span class="comment"># 调用后，中间消息'm'将被清除。上述函数的数学公式为：</span></span><br><span class="line">    <span class="comment"># g的nodes和edges特征不变</span></span><br><span class="line">    fn.u_add_v(<span class="string">'feat'</span>, <span class="string">'feat'</span>, <span class="string">'m'</span>)</span><br><span class="line">    fn.sum(<span class="string">'m'</span>, <span class="string">'h'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># update_all可以从mailbox中聚合消息，并将其保存在目标节点上</span></span><br><span class="line">    <span class="comment"># 消息函数和聚合函数进行了消息融合，避免产生中间结果占用内存</span></span><br><span class="line">    <span class="comment"># g的nodes特征增添了聚合结果'h'</span></span><br><span class="line">    g.update_all(fn.u_add_v(<span class="string">'feat'</span>, <span class="string">'feat'</span>, <span class="string">'m'</span>),</span><br><span class="line">                 fn.sum(<span class="string">'m'</span>, <span class="string">'h'</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过 apply_edges() 调用消息函数，消息传递结果会保存在边上</span></span><br><span class="line">    <span class="comment"># g的nodes特征增添了计算结果'a'</span></span><br><span class="line">    g.apply_edges(fn.u_add_v(<span class="string">'feat'</span>, <span class="string">'feat'</span>, <span class="string">'a'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    g2 = dgl.graph((u,v))</span><br><span class="line">    g2.ndata[<span class="string">'feat'</span>] = th.ones(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">    g2.edata[<span class="string">'a'</span>] = th.ones(<span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line">    updated_g2 = updata_all_example(g2)</span><br><span class="line">    print(g2.ndata)</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">    &#123;'feat': tensor([[0., 0.],</span></span><br><span class="line"><span class="string">        [2., 2.],</span></span><br><span class="line"><span class="string">        [2., 2.],</span></span><br><span class="line"><span class="string">        [2., 2.],</span></span><br><span class="line"><span class="string">        [2., 2.]])&#125;</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    g3 = dgl.graph((u,v))</span><br><span class="line">    g3.ndata[<span class="string">'feat'</span>] = th.ones(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 因此，直接调用消息函数和聚合函数无意义</span></span><br><span class="line">    <span class="comment"># 使用g.update_all()或g.apply_edges(),将消息函数和聚合函数作为参数调用(无需传参)</span></span><br><span class="line">    g3.update_all(message_func, reduce_func)</span><br><span class="line">    print(g3.ndata)</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">    &#123;'feat': tensor([[0., 0.],</span></span><br><span class="line"><span class="string">        [2., 2.],</span></span><br><span class="line"><span class="string">        [2., 2.],</span></span><br><span class="line"><span class="string">        [2., 2.],</span></span><br><span class="line"><span class="string">        [2., 2.]])&#125;</span></span><br><span class="line"><span class="string">    '''</span></span><br></pre></td></tr></table></figure>
<h2 id="22-编写高效地消息传递代码"><a class="markdownIt-Anchor" href="#22-编写高效地消息传递代码"></a> 2.2 编写高效地消息传递代码</h2>
<p>DGL建议用户尽量减少<strong>边</strong>的特征维数。下面是一个如何通过<strong>对节点特征降维来减少消息维度</strong>的示例。该做法执行以下操作：拼接 <code>源</code> 节点和 <code>目标</code> 节点特征（按照dim=-1拼接，n不变），然后应用一个线性层，即 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi><mo>×</mo><mo stretchy="false">(</mo><mi>u</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W\times (u || v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span>。 <code>源</code> 节点和 <code>目标</code> 节点特征维数较高，而线性层输出维数较低。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> dgl.function <span class="keyword">as</span> fn</span><br><span class="line"></span><br><span class="line"><span class="comment"># random graph with 5 nodes and 6 edges</span></span><br><span class="line">graph = dgl.rand_graph(<span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line">graph.ndata[<span class="string">'feat'</span>] = th.ones(<span class="number">5</span>, <span class="number">8</span>)</span><br><span class="line">in_dim = <span class="number">8</span></span><br><span class="line">out_dim = <span class="number">3</span></span><br><span class="line">w_l = nn.Parameter(th.FloatTensor(size=(in_dim, out_dim)))</span><br><span class="line">w_r = nn.Parameter(th.FloatTensor(size=(in_dim, out_dim)))</span><br><span class="line">w = th.cat([w_l, w_r], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现方法一</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">concat</span><span class="params">(edges)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'h'</span>: th.cat([edges.src[<span class="string">'feat'</span>], edges.dst[<span class="string">'feat'</span>]], <span class="number">-1</span>)&#125;</span><br><span class="line">graph.apply_edges(concat)</span><br><span class="line">graph.edata[<span class="string">'e'</span>] = graph.edata[<span class="string">'h'</span>] @ w</span><br><span class="line">print(graph.edata[<span class="string">'e'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现方法二</span></span><br><span class="line">graph.srcdata[<span class="string">'h_src'</span>] = graph.ndata[<span class="string">'feat'</span>] @ w_l</span><br><span class="line">graph.dstdata[<span class="string">'h_dst'</span>] = graph.ndata[<span class="string">'feat'</span>] @ w_r</span><br><span class="line">graph.apply_edges(fn.u_add_v(<span class="string">'h_src'</span>, <span class="string">'h_dst'</span>, <span class="string">'e'</span>))</span><br><span class="line">print(graph.edata[<span class="string">'e'</span>])</span><br></pre></td></tr></table></figure>
<p>其中，第二种方法将线性操作分成两部分，一个应用于 <code>源</code> 节点特征，另一个应用于 <code>目标</code> 节点特征。 在最后一个阶段，在边上将以上两部分线性操作的结果相加，即执行 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>l</mi></msub><mo>×</mo><mi>u</mi><mo>+</mo><msub><mi>W</mi><mi>r</mi></msub><mo>×</mo><mi>v</mi></mrow><annotation encoding="application/x-tex">W_l\times u + W_r \times v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">u</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span></span></span>， 因为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi><mo>×</mo><mo stretchy="false">(</mo><mi>u</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><msub><mi>W</mi><mi>l</mi></msub><mo>×</mo><mi>u</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>r</mi></msub><mo>×</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W \times (u||v) = (W_l \times u) || (W_r \times v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">u</span><span class="mclose">)</span><span class="mord">∣</span><span class="mord">∣</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">w_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">w_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 分别是矩阵 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span> 的左半部分和右半部分：</p>
<p>以上两个实现在数学上是等价的。后一种方法效率高得多，因为不需要在边上保存concatenate之后的结果（前面说过DGL在边上保存信息是十分消耗内存的）， 从内存角度来说是高效的。另外，加法可以通过DGL的内置函数 <code>u_add_v</code> 进行优化，从而进一步加快计算速度并节省内存占用。</p>
<p><strong>总之，该示例是为了说明在编写DGL模型时，应注意尽量不要在边上保存信息，尽量使用内置函数。</strong></p>
<p>[注] 关于g.srcdata[‘feat’]和g.dstdata[‘feat’]：</p>
<ul>
<li>在异构图中，g.srcdata[‘feat’] 可以表示单种或多种源节点的feature；g.dstdata[‘feat’]同理</li>
<li>而在同构图中，g.srcdata[‘feat’] 和g.dstdata[‘feat’] 均表示所有节点的feature</li>
</ul>
<h2 id="23-在图的一部分上进行消息传递"><a class="markdownIt-Anchor" href="#23-在图的一部分上进行消息传递"></a> 2.3 在图的一部分上进行消息传递</h2>
<p>如果用户只想更新图中的部分节点，可以先通过想要囊括的节点编号创建一个子图， 然后在子图上调用 <a href="https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.update_all.html#dgl.DGLGraph.update_all" target="_blank" rel="noopener"><code>update_all()</code></a> 方法。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nid = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">9</span>]</span><br><span class="line">sg = g.subgraph(nid)</span><br><span class="line">sg.update_all(message_func, reduce_func)</span><br><span class="line">apply_node_func()</span><br></pre></td></tr></table></figure>
<h2 id="24-在消息传递中使用边的权重"><a class="markdownIt-Anchor" href="#24-在消息传递中使用边的权重"></a> 2.4 在消息传递中使用边的权重</h2>
<p>一类常见的图神经网络建模的做法是在消息聚合前使用边的权重， 比如在 <a href="https://arxiv.org/pdf/1710.10903.pdf" target="_blank" rel="noopener">图注意力网络(GAT)</a> 和一些 <a href="https://arxiv.org/abs/2004.00445" target="_blank" rel="noopener">GCN的变种</a>。DGL的处理方法是：</p>
<ul>
<li>将权重存为边的特征。</li>
<li>在消息函数中用边的特征与源节点的特征相乘。</li>
</ul>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl.function <span class="keyword">as</span> fn</span><br><span class="line"></span><br><span class="line">graph.edata[<span class="string">'a'</span>] = th.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">graph.update_all(fn.u_mul_e(<span class="string">'ft'</span>, <span class="string">'a'</span>, <span class="string">'m'</span>),</span><br><span class="line">                 fn.sum(<span class="string">'m'</span>, <span class="string">'ft'</span>))</span><br></pre></td></tr></table></figure>
<h2 id="25-在异构图上进行消息传递"><a class="markdownIt-Anchor" href="#25-在异构图上进行消息传递"></a> 2.5 在异构图上进行消息传递</h2>
<p>异构图上的消息传递可以分为两个部分：</p>
<p>（1）对每个关系计算和聚合消息。</p>
<p>（2）对每个结点聚合来自不同关系的消息。</p>
<p>在DGL中，对异构图进行消息传递的接口是 <a href="https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.multi_update_all.html#dgl.DGLGraph.multi_update_all" target="_blank" rel="noopener"><code>multi_update_all()</code></a>。 <a href="https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.multi_update_all.html#dgl.DGLGraph.multi_update_all" target="_blank" rel="noopener"><code>multi_update_all()</code></a> 接受一个字典。这个字典的每一个键值对里，键是一种关系， 值是这种关系对应 <a href="https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.update_all.html#dgl.DGLGraph.update_all" target="_blank" rel="noopener"><code>update_all()</code></a> 的参数。 <a href="https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.multi_update_all.html#dgl.DGLGraph.multi_update_all" target="_blank" rel="noopener"><code>multi_update_all()</code></a> 还接受一个字符串来表示跨类型整合函数，来指定整合不同关系聚合结果的方式。 这个整合方式可以是 <code>sum</code>、 <code>min</code>、 <code>max</code>、 <code>mean</code> 和 <code>stack</code> 中的一个。以下是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl.function <span class="keyword">as</span> fn</span><br><span class="line"></span><br><span class="line"><span class="comment"># g.canonical_etypes返回包括两端节点在内的完整的三元组异构图edge</span></span><br><span class="line"><span class="comment"># g.etypes仅返回edge本身</span></span><br><span class="line">g = dgl.heterograph(&#123;(<span class="string">'user'</span>, <span class="string">'follows'</span>, <span class="string">'user'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>])),</span><br><span class="line">                     (<span class="string">'user'</span>, <span class="string">'follows'</span>, <span class="string">'game'</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])),</span><br><span class="line">                     (<span class="string">'user'</span>, <span class="string">'plays'</span>, <span class="string">'game'</span>): (th.tensor([<span class="number">1</span>, <span class="number">3</span>]), th.tensor([<span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line">                     &#125;)</span><br><span class="line">funcs = &#123;&#125;</span><br><span class="line">g.srcdata[<span class="string">'feat'</span>]=&#123;<span class="string">'user'</span>: th.ones(<span class="number">4</span>, <span class="number">1</span>),</span><br><span class="line">                   <span class="string">'game'</span>: th.ones(<span class="number">4</span>, <span class="number">1</span>)&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> c_etype <span class="keyword">in</span> g.canonical_etypes:</span><br><span class="line">    srctype, etype, dsttype = c_etype</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 指定每个关系的消息传递函数：(message_func, reduce_func).</span></span><br><span class="line">    <span class="comment"># 注意结果保存在同一个目标特征“h”，说明聚合是逐类进行的。</span></span><br><span class="line">    funcs[c_etype] = (fn.copy_u(<span class="string">'feat'</span>, <span class="string">'m'</span>), fn.mean(<span class="string">'m'</span>, <span class="string">'h'</span>))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 将每个类型消息聚合的结果相加。</span></span><br><span class="line">g.multi_update_all(funcs, <span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line">print(g.ndata)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">&#123;'game': &#123;'feat': tensor([[1.], [1.], [1.], [1.]]), </span></span><br><span class="line"><span class="string">          'h': tensor([[0.], [1.], [2.], [2.]])&#125;, </span></span><br><span class="line"><span class="string"> 'user': &#123;'feat': tensor([[1.], [1.], [1.], [1.]]), </span></span><br><span class="line"><span class="string">          'h': tensor([[0.], [1.], [1.], [0.]])&#125;</span></span><br><span class="line"><span class="string"> &#125;</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Alston</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://lizitong67.github.io/2021/03/17/Deep-Graph-Library/">https://lizitong67.github.io/2021/03/17/Deep-Graph-Library/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://lizitong67.github.io">Alston's blog</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DGL/">DGL</a></div><nav id="pagination"><div class="next-post pull-right"><a href="/2021/03/15/DGL%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-GraphSAGE/"><span>DGL源码解析-GraphSAGE</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://s3.ax1x.com/2021/03/14/60DEdJ.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2020 - 2021 By Alston</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>