<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Python3爬虫笔记-requests"><meta name="keywords" content="Python,爬虫"><meta name="author" content="Alston"><meta name="copyright" content="Alston"><title>Python3爬虫笔记-requests | Alston's blog</title><link rel="shortcut icon" href="/1231489.png"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-get请求"><span class="toc-text"> 1 GET请求</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-抓取网页"><span class="toc-text"> 1.1 抓取网页</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-抓取二进制数据"><span class="toc-text"> 1.2 抓取二进制数据</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-post请求"><span class="toc-text"> 2 POST请求</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-响应"><span class="toc-text"> 3 响应</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-高级用法"><span class="toc-text"> 4 高级用法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#41-文件上传"><span class="toc-text"> 4.1 文件上传</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#42-cookies"><span class="toc-text"> 4.2 Cookies</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#43-会话维持"><span class="toc-text"> 4.3 会话维持</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#44-ssl证书验证"><span class="toc-text"> 4.4 SSL证书验证</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#45-代理设置"><span class="toc-text"> 4.5 代理设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#46-超时设置"><span class="toc-text"> 4.6 超时设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#47-身份认证"><span class="toc-text"> 4.7 身份认证</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#48-prepared-request"><span class="toc-text"> 4.8 Prepared Request</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://pic4.zhimg.com/80/v2-1b0d0240350e3d8e0550845b6bdaad1e_hd.jpg"></div><div class="author-info__name text-center">Alston</div><div class="author-info__description text-center">计算机硕士在读</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">47</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">26</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">13</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://blog.csdn.net/Sc0fie1d" target="_blank" rel="noopener">Alston's CSDN</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://images.pexels.com/photos/1252869/pexels-photo-1252869.jpeg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Alston's blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">Python3爬虫笔记-requests</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-02-21</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Python/">Python</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">1.4k</span><span class="post-meta__separator">|</span><span>阅读时长: 6 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><ul>
<li>在request中，所有的请求都可以用以请求名称命名的方法来调用：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = requests.get(<span class="string">'https://www.baidu.com/'</span>)</span><br><span class="line">r = requests.post(<span class="string">'http://httpbin.org/post'</span>)</span><br><span class="line">r = requests.put(<span class="string">'http://httpbin.org/put'</span>)</span><br><span class="line">r = requests.delete(<span class="string">'http://httpbin.org/delete'</span>)</span><br><span class="line">r = requests.head(<span class="string">'http://httpbin.org/get'</span>)</span><br><span class="line">r = requests.options(<span class="string">'http://httpbin.org/get'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="1-get请求"><a class="markdownIt-Anchor" href="#1-get请求"></a> 1 GET请求</h1>
<ul>
<li>利用<kbd>params</kbd>参数，构造字典来传递GET参数。请求的链接自动被构造成了|<code>http://httpbin.org/get?age=22&amp;name=germey</code>|：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'germey'</span>,</span><br><span class="line">    <span class="string">'age'</span>: <span class="number">22</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">"http://httpbin.org/get"</span>, params=data)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>另外，网页的返回类型实际上是str类型，但是它很特殊，是JSON格式的。所以，如果想直接解析返回结果，得到一个字典格式的话，可以直接调用json()方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line">r = requests.get(<span class="string">"http://httpbin.org/get"</span>)</span><br><span class="line">print(type(r.text))</span><br><span class="line">print(r.json())</span><br><span class="line">print(type(r.json()))</span><br><span class="line"></span><br><span class="line"><span class="comment">#运行结果：</span></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">str</span>'&gt;</span></span><br><span class="line">&#123;'headers': &#123;'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.10.0'&#125;, 'url': 'http://httpbin.org/get', 'args': &#123;&#125;, 'origin': '182.33.248.131'&#125;</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">dict</span>'&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="11-抓取网页"><a class="markdownIt-Anchor" href="#11-抓取网页"></a> 1.1 抓取网页</h2>
<ul>
<li>以爬取知乎为例，读取页面内容，并用正则表达式匹配相应内容。注意爬去知乎必须要修改User-Agent，否则知乎拒绝访问。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">"https://www.zhihu.com/explore"</span>, headers=headers)</span><br><span class="line">pattern = re.compile(<span class="string">'explore-feed.*?question_link.*?&gt;(.*?)&lt;/a&gt;'</span>, re.S)</span><br><span class="line">titles = re.findall(pattern, r.text)</span><br><span class="line">print(titles)</span><br></pre></td></tr></table></figure>
<h2 id="12-抓取二进制数据"><a class="markdownIt-Anchor" href="#12-抓取二进制数据"></a> 1.2 抓取二进制数据</h2>
<ul>
<li>图片、视频、音频等都是以二进制数据存储的。要抓去它们必须拿到它们的二进制码。</li>
<li>下面以抓取GitHub图标为例：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">"https://github.com/favicon.ico"</span>)</span><br><span class="line">print(r.text)</span><br><span class="line">print(r.content)</span><br><span class="line"></span><br><span class="line"><span class="comment">#第一行会输出乱码，因为text()输出字符串，而抓取的是图片数据</span></span><br><span class="line"><span class="comment">#第二行会输出bytes数据，content()输出bytes数据</span></span><br></pre></td></tr></table></figure>
<ul>
<li>下面的代码读取图片，在本地打开一个favicon.ico的文件，wb表示以bytes格式写入。然后将图片的字节流写入文件，该文件打开后就是抓取到的图片。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">"https://github.com/favicon.ico"</span>)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'favicon.ico'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(r.content)</span><br></pre></td></tr></table></figure>
<h1 id="2-post请求"><a class="markdownIt-Anchor" href="#2-post请求"></a> 2 POST请求</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">data = &#123;<span class="string">'name'</span>: <span class="string">'germey'</span>, <span class="string">'age'</span>: <span class="string">'22'</span>&#125;</span><br><span class="line">r = requests.post(<span class="string">"http://httpbin.org/post"</span>, data=data)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<h1 id="3-响应"><a class="markdownIt-Anchor" href="#3-响应"></a> 3 响应</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'http://www.jianshu.com'</span>)</span><br><span class="line">print(type(r.status_code), r.status_code)</span><br><span class="line">print(type(r.headers), r.headers)</span><br><span class="line">print(type(r.cookies), r.cookies)</span><br><span class="line">print(type(r.url), r.url)</span><br><span class="line">print(type(r.history), r.history)</span><br></pre></td></tr></table></figure>
<ul>
<li>下面的代码中，状态码200可以用<kbd>requests.codes.ok</kbd>来比对；404可以用<kbd>requests.codes.not_found</kbd>来比对等等：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'http://www.jianshu.com'</span>)</span><br><span class="line">exit() <span class="keyword">if</span> <span class="keyword">not</span> r.status_code == requests.codes.ok <span class="keyword">else</span> print(<span class="string">'Request Successfully'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="4-高级用法"><a class="markdownIt-Anchor" href="#4-高级用法"></a> 4 高级用法</h1>
<h2 id="41-文件上传"><a class="markdownIt-Anchor" href="#41-文件上传"></a> 4.1 文件上传</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">files = &#123;<span class="string">'file'</span>: open(<span class="string">'favicon.ico'</span>, <span class="string">'rb'</span>)&#125;</span><br><span class="line">r = requests.post(<span class="string">"http://httpbin.org/post"</span>, files=files)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<h2 id="42-cookies"><a class="markdownIt-Anchor" href="#42-cookies"></a> 4.2 Cookies</h2>
<ul>
<li>代码中，items()将字典中的每一对键值转化为元组，返回一个多个元组组成的列表：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">"https://www.baidu.com"</span>)</span><br><span class="line">print(r.cookies)</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> r.cookies.items():</span><br><span class="line">    print(key + <span class="string">'='</span> + value)</span><br></pre></td></tr></table></figure>
<h2 id="43-会话维持"><a class="markdownIt-Anchor" href="#43-会话维持"></a> 4.3 会话维持</h2>
<ul>
<li>设想这样一个场景，第一个请求利用post()方法登录了某个网站，第二次想获取成功登录后的自己的个人信息，你又用了一次get()方法去请求个人信息页面。实际上，这相当于打开了两个浏览器，是两个完全不相关的会话，能成功获取个人信息吗？那当然不能。</li>
<li>利用<kbd>Session</kbd>便可以实现这个功能，维持同一个会话。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">s = requests.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置了浏览器的cookie</span></span><br><span class="line">s.get(<span class="string">'http://httpbin.org/cookies/set/number/123456789'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#可以直接获取到cookie，因为是在同一个会话中</span></span><br><span class="line">r = s.get(<span class="string">'http://httpbin.org/cookies'</span>)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<h2 id="44-ssl证书验证"><a class="markdownIt-Anchor" href="#44-ssl证书验证"></a> 4.4 SSL证书验证</h2>
<ul>
<li>对于证书没有被官方CA机构信任的网站，直接访问会报错；</li>
<li>把<kbd>verify</kbd>参数设置为<kbd>False</kbd>即可：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line">response = requests.get(<span class="string">'https://www.12306.cn'</span>, verify=<span class="literal">False</span>)</span><br><span class="line">print(response.status_code)</span><br></pre></td></tr></table></figure>
<h2 id="45-代理设置"><a class="markdownIt-Anchor" href="#45-代理设置"></a> 4.5 代理设置</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">  <span class="string">"http"</span>: <span class="string">"http://10.10.1.10:3128"</span>,</span><br><span class="line">  <span class="string">"https"</span>: <span class="string">"http://10.10.1.10:1080"</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">requests.get(<span class="string">"https://www.taobao.com"</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>
<ul>
<li>若代理需要使用HTTP Basic Auth，可以使用类似|<code>http://user:password@host:port</code>|这样的语法来设置代理，示例如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">"http"</span>: <span class="string">"http://user:password@10.10.1.10:3128/"</span>,</span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">"https://www.taobao.com"</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>
<ul>
<li>除了基本的HTTP代理外，requests还支持SOCKS协议的代理。</li>
<li>首先，需要安装socks这个库：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip3 install &#39;requests[socks]&#39;</span><br></pre></td></tr></table></figure>
<ul>
<li>然后就可以使用SOCKS协议代理了，示例如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">'http'</span>: <span class="string">'socks5://user:password@host:port'</span>,</span><br><span class="line">    <span class="string">'https'</span>: <span class="string">'socks5://user:password@host:port'</span></span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">"https://www.taobao.com"</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>
<h2 id="46-超时设置"><a class="markdownIt-Anchor" href="#46-超时设置"></a> 4.6 超时设置</h2>
<p>i</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mport requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">"https://www.taobao.com"</span>, timeout = <span class="number">1</span>)</span><br><span class="line">print(r.status_code)</span><br></pre></td></tr></table></figure>
<h2 id="47-身份认证"><a class="markdownIt-Anchor" href="#47-身份认证"></a> 4.7 身份认证</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line">r = requests.get(<span class="string">'http://localhost:5000'</span>, auth=(<span class="string">'username'</span>, <span class="string">'password'</span>))</span><br><span class="line">print(r.status_code)</span><br><span class="line"></span><br><span class="line"><span class="comment">#auth=()实际上是调用了 requests.auth.HTTPBasicAuth 库中的 auth=HTTPBasicAuth('username', 'password')</span></span><br></pre></td></tr></table></figure>
<h2 id="48-prepared-request"><a class="markdownIt-Anchor" href="#48-prepared-request"></a> 4.8 Prepared Request</h2>
<ul>
<li>在requests中也可以将请求表示为数据结构，这个数据结构称为Prepared Request</li>
<li>这里我们引入了Request，然后用url、data和headers参数构造了一个Request对象，这时需要再调用Session的prepare_request()方法将其转换为一个Prepared Request对象，然后调用send()方法发送即可：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> requests <span class="keyword">import</span> Request, Session</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://httpbin.org/post'</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'germey'</span></span><br><span class="line">&#125;</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line">s = Session()</span><br><span class="line">req = Request(<span class="string">'POST'</span>, url, data=data, headers=headers)</span><br><span class="line">prepped = s.prepare_request(req)</span><br><span class="line">r = s.send(prepped)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<ul>
<li>有了Request这个对象，就可以将请求当作独立的对象来看待，这样在进行队列调度时会非常方便。</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Alston</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://lizitong67.github.io/2020/02/21/Python3%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0-requests/">https://lizitong67.github.io/2020/02/21/Python3%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0-requests/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://lizitong67.github.io">Alston's blog</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/02/21/Python3%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"><i class="fa fa-chevron-left">  </i><span>Python3爬虫笔记-正则表达式</span></a></div><div class="next-post pull-right"><a href="/2020/02/21/Python3%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0-urllib/"><span>Python3爬虫笔记-urllib</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://images.pexels.com/photos/1252869/pexels-photo-1252869.jpeg)"><div class="layout" id="footer"><div class="copyright">&copy;2020 - 2021 By Alston</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>